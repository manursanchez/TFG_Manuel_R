{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capítulo 6\n",
    "\n",
    "6.4 Patrones de unión.\n",
    "\n",
    "6.4.3 Unión externa \n",
    "\n",
    "6.4.3.1 Unión externa por la izquierda\n",
    "\n",
    "Patrón que permite realizar una unión por la izquierda de dos tablas de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing unionIzquierda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile unionIzquierda.py\n",
    "#!/usr/bin/env python\n",
    "from mrjob.job import MRJob\n",
    "import re,sys,os\n",
    "\n",
    "class unionIzquierda(MRJob):\n",
    "    \n",
    "    def limpiarNombreArchivo(self,archivo):\n",
    "        encontradaBarra=False\n",
    "        tamano=len(archivo)\n",
    "        posicion=tamano-1\n",
    "        while encontradaBarra==False or posicion==0:\n",
    "            if archivo[posicion]==\"/\":\n",
    "                encontradaBarra=True\n",
    "                return archivo[posicion+1:tamano]\n",
    "            else:\n",
    "                posicion-=1\n",
    "        if posicion==0:\n",
    "            return archivo\n",
    "        \n",
    "    def mapper_init(self):\n",
    "        self.namefile=self.limpiarNombreArchivo(os.getenv('map_input_file')) \n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        clave=\"\"\n",
    "        linea=line.split(';')\n",
    "        encontrado=re.search('[a-zA-Z]',linea[0])\n",
    "        if encontrado==None:\n",
    "            if self.namefile==\"tiendas.csv\":\n",
    "                linea.append(self.namefile)\n",
    "                clave=linea[0] #Esta clave es la común de la tabla 1\n",
    "                yield clave,linea\n",
    "            else:\n",
    "                linea.append('art.csv') #se recorta el nombre del archivo para mejorar la legibilidad de la salida\n",
    "                clave=linea[1] #Clave común de la tabla 2\n",
    "                yield clave,linea\n",
    "       \n",
    "    ############# Reducer ############################\n",
    "        \n",
    "    def reducer(self,key,values):\n",
    "        listaA=[]\n",
    "        listaB=[]\n",
    "        #Llenamos las dos listas\n",
    "        for valor in values:\n",
    "            if valor[len(valor)-1]==\"tiendas.csv\":\n",
    "                listaA.append(valor)\n",
    "            else:\n",
    "                listaB.append(valor)\n",
    "        \n",
    "        ###### Union por la izquierda ######\n",
    "        for valorA in listaA:\n",
    "            if listaB:\n",
    "                for valorB in listaB:\n",
    "                    yield valorA, valorB\n",
    "            else:\n",
    "                #Si la listaB está vacía\n",
    "                yield valorA, \"null\" \n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    unionIzquierda.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/unionIzquierda.root.20201214.221444.910643\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/unionIzquierda.root.20201214.221444.910643/output\n",
      "Streaming final output from /tmp/unionIzquierda.root.20201214.221444.910643/output...\n",
      "[\"3\", \"Granada\", \"tiendas.csv\"]\t[\"1006\", \"3\", \"3\", \"art.csv\"]\n",
      "[\"3\", \"Granada\", \"tiendas.csv\"]\t[\"1010\", \"3\", \"20\", \"art.csv\"]\n",
      "[\"6\", \"Barcelona\", \"tiendas.csv\"]\t\"null\"\n",
      "[\"2\", \"Albacete\", \"tiendas.csv\"]\t[\"1002\", \"2\", \"10\", \"art.csv\"]\n",
      "[\"2\", \"Albacete\", \"tiendas.csv\"]\t[\"1005\", \"2\", \"5\", \"art.csv\"]\n",
      "[\"2\", \"Albacete\", \"tiendas.csv\"]\t[\"1008\", \"2\", \"5\", \"art.csv\"]\n",
      "[\"1\", \"Santander\", \"tiendas.csv\"]\t[\"1001\", \"1\", \"20\", \"art.csv\"]\n",
      "[\"1\", \"Santander\", \"tiendas.csv\"]\t[\"1003\", \"1\", \"15\", \"art.csv\"]\n",
      "[\"1\", \"Santander\", \"tiendas.csv\"]\t[\"1007\", \"1\", \"8\", \"art.csv\"]\n",
      "Removing temp directory /tmp/unionIzquierda.root.20201214.221444.910643...\n"
     ]
    }
   ],
   "source": [
    "!python unionIzquierda.py archivos_datos/tiendas-articulos/tiendas.csv archivos_datos/tiendas-articulos/articulos_stock.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJECUCIÓN EN EL CLUSTER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /usr/lib/hadoop/bin...\n",
      "Found hadoop binary: /usr/lib/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/unionIzquierda.root.20201214.223814.456168\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/unionIzquierda.root.20201214.223814.456168/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/unionIzquierda.root.20201214.223814.456168/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob7549110537948998925.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.5:8032\n",
      "  Total input paths to process : 2\n",
      "  number of splits:3\n",
      "  Submitting tokens for job: job_1607985144237_0001\n",
      "  Submitted application application_1607985144237_0001\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1607985144237_0001/\n",
      "  Running job: job_1607985144237_0001\n",
      "  Job job_1607985144237_0001 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1607985144237_0001 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/unionIzquierda.root.20201214.223814.456168/output\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=225\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=550\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=528\n",
      "\t\tFILE: Number of bytes written=594721\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=538\n",
      "\t\tHDFS: Number of bytes written=550\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=12\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=3\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=132385792\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=21865472\n",
      "\t\tTotal time spent by all map tasks (ms)=129283\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=129283\n",
      "\t\tTotal time spent by all reduce tasks (ms)=21353\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=21353\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=129283\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=21353\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=6630\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=1927\n",
      "\t\tInput split bytes=313\n",
      "\t\tMap input records=16\n",
      "\t\tMap output bytes=494\n",
      "\t\tMap output materialized bytes=540\n",
      "\t\tMap output records=14\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tPhysical memory (bytes) snapshot=976121856\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=14\n",
      "\t\tReduce output records=9\n",
      "\t\tReduce shuffle bytes=540\n",
      "\t\tShuffled Maps =3\n",
      "\t\tSpilled Records=28\n",
      "\t\tTotal committed heap usage (bytes)=828375040\n",
      "\t\tVirtual memory (bytes) snapshot=10513506304\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///user/root/tmp/mrjob/unionIzquierda.root.20201214.223814.456168/output\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/unionIzquierda.root.20201214.223814.456168/output...\n",
      "[\"1\", \"Santander\", \"tiendas.csv\"]\t[\"1007\", \"1\", \"8\", \"art.csv\"]\n",
      "[\"1\", \"Santander\", \"tiendas.csv\"]\t[\"1003\", \"1\", \"15\", \"art.csv\"]\n",
      "[\"1\", \"Santander\", \"tiendas.csv\"]\t[\"1001\", \"1\", \"20\", \"art.csv\"]\n",
      "[\"2\", \"Albacete\", \"tiendas.csv\"]\t[\"1005\", \"2\", \"5\", \"art.csv\"]\n",
      "[\"2\", \"Albacete\", \"tiendas.csv\"]\t[\"1002\", \"2\", \"10\", \"art.csv\"]\n",
      "[\"2\", \"Albacete\", \"tiendas.csv\"]\t[\"1008\", \"2\", \"5\", \"art.csv\"]\n",
      "[\"3\", \"Granada\", \"tiendas.csv\"]\t[\"1006\", \"3\", \"3\", \"art.csv\"]\n",
      "[\"3\", \"Granada\", \"tiendas.csv\"]\t[\"1010\", \"3\", \"20\", \"art.csv\"]\n",
      "[\"6\", \"Barcelona\", \"tiendas.csv\"]\t\"null\"\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/unionIzquierda.root.20201214.223814.456168...\n",
      "Removing temp directory /tmp/unionIzquierda.root.20201214.223814.456168...\n"
     ]
    }
   ],
   "source": [
    "!python unionIzquierda.py hdfs:///archivos_datos/articulos_stock.csv hdfs:///archivos_datos/tiendas.csv -r hadoop --python-bin /opt/anaconda/bin/python3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
