{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capítulo 6\n",
    "\n",
    "6.4 Patrones de unión.\n",
    "\n",
    "6.4.5 Producto cartesiano \n",
    "\n",
    "Prototipo para el cálculo del producto cartesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing productoCartesiano.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile productoCartesiano.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import re,os\n",
    "\n",
    "class productoCartesiano(MRJob):\n",
    "   \n",
    "    def limpiarNombreArchivo(self,archivo):\n",
    "        encontradaBarra=False\n",
    "        tamano=len(archivo)\n",
    "        posicion=tamano-1\n",
    "        while encontradaBarra==False or posicion==0:\n",
    "            if archivo[posicion]==\"/\":\n",
    "                encontradaBarra=True\n",
    "                return archivo[posicion+1:tamano]\n",
    "            else:\n",
    "                posicion-=1\n",
    "        if posicion==0:\n",
    "            return archivo\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        self.namefile=self.limpiarNombreArchivo(os.getenv('map_input_file')) \n",
    "        \n",
    "    def mapper(self,_,line):\n",
    "        linea=line.split(';')\n",
    "        encontrado=re.search('[a-zA-Z]',linea[0])\n",
    "        if encontrado==None:\n",
    "            if self.namefile==\"tiendas.csv\":\n",
    "                linea.append(\"file_1\")#Añadimos identificador de archivo\n",
    "                yield \"llave\",linea #Llave única \n",
    "            else:\n",
    "                linea.append(\"file_2\") \n",
    "                yield \"llave\",linea #Llave única\n",
    "        \n",
    "    def reducer(self,key,values):\n",
    "        listaA=[]\n",
    "        listaB=[]\n",
    "        #Llenamos las dos listas\n",
    "        for valor in values:\n",
    "            if valor[len(valor)-1]==\"file_1\":\n",
    "                listaA.append(valor)\n",
    "            else:\n",
    "                listaB.append(valor)\n",
    "        \n",
    "        ########## Producto Cartesiano ###########\n",
    "        if listaA and listaB:\n",
    "            for valor_A in listaA:\n",
    "                for valor_B in listaB:\n",
    "                    yield key,(valor_A, valor_B)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    productoCartesiano.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/productoCartesiano.root.20201214.225848.310553\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/productoCartesiano.root.20201214.225848.310553/output\n",
      "Streaming final output from /tmp/productoCartesiano.root.20201214.225848.310553/output...\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "Removing temp directory /tmp/productoCartesiano.root.20201214.225848.310553...\n"
     ]
    }
   ],
   "source": [
    "!python productoCartesiano.py archivos_datos/tiendas-articulos/tiendas.csv archivos_datos/tiendas-articulos/articulos_stock.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJECUCIÓN EN EL CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /usr/lib/hadoop/bin...\n",
      "Found hadoop binary: /usr/lib/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/productoCartesiano.root.20201214.225944.499035\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/productoCartesiano.root.20201214.225944.499035/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/productoCartesiano.root.20201214.225944.499035/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob7229779203725021077.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.5:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.5:8032\n",
      "  Total input paths to process : 2\n",
      "  number of splits:3\n",
      "  Submitting tokens for job: job_1607985144237_0005\n",
      "  Submitted application application_1607985144237_0005\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1607985144237_0005/\n",
      "  Running job: job_1607985144237_0005\n",
      "  Job job_1607985144237_0005 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1607985144237_0005 completed successfully\n",
      "  Output directory: hdfs:///user/root/tmp/mrjob/productoCartesiano.root.20201214.225944.499035/output\n",
      "Counters: 50\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=225\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2750\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=554\n",
      "\t\tFILE: Number of bytes written=594997\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=538\n",
      "\t\tHDFS: Number of bytes written=2750\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=12\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=3\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=83720192\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=11301888\n",
      "\t\tTotal time spent by all map tasks (ms)=81758\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=81758\n",
      "\t\tTotal time spent by all reduce tasks (ms)=11037\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=11037\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=81758\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=11037\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=5780\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=1772\n",
      "\t\tInput split bytes=313\n",
      "\t\tMap input records=16\n",
      "\t\tMap output bytes=520\n",
      "\t\tMap output materialized bytes=566\n",
      "\t\tMap output records=14\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tPhysical memory (bytes) snapshot=1049931776\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=14\n",
      "\t\tReduce output records=40\n",
      "\t\tReduce shuffle bytes=566\n",
      "\t\tShuffled Maps =3\n",
      "\t\tSpilled Records=28\n",
      "\t\tTotal committed heap usage (bytes)=852492288\n",
      "\t\tVirtual memory (bytes) snapshot=10518306816\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///user/root/tmp/mrjob/productoCartesiano.root.20201214.225944.499035/output\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/productoCartesiano.root.20201214.225944.499035/output...\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"6\", \"Barcelona\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"3\", \"Granada\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"2\", \"Albacete\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1010\", \"3\", \"20\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1009\", \"4\", \"1\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1008\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1007\", \"1\", \"8\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1006\", \"3\", \"3\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1005\", \"2\", \"5\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1004\", \"5\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1003\", \"1\", \"15\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1002\", \"2\", \"10\", \"file_2\"]]\n",
      "\"llave\"\t[[\"1\", \"Santander\", \"file_1\"], [\"1001\", \"1\", \"20\", \"file_2\"]]\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/productoCartesiano.root.20201214.225944.499035...\n",
      "Removing temp directory /tmp/productoCartesiano.root.20201214.225944.499035...\n"
     ]
    }
   ],
   "source": [
    "!python productoCartesiano.py hdfs:///archivos_datos/articulos_stock.csv hdfs:///archivos_datos/tiendas.csv -r hadoop --python-bin /opt/anaconda/bin/python3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
