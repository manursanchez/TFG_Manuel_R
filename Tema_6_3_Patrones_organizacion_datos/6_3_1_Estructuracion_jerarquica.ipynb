{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capítulo 6\n",
    "\n",
    "6.3 Patrones de organización de datos.\n",
    "\n",
    "6.3.1 Estructuración jerárquica\n",
    "\n",
    "Prototipo - Este ejemplo de patrón de organización de datos consiste en que dada una estructura de datos en formato tabla, ésta es convertida a otro tipo de estructura en un formato jerarquizado XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing jerarquico.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile jerarquico.py\n",
    "#!/usr/bin/env python\n",
    "#Usamos el archivo foros.csv\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol\n",
    "import xmlify\n",
    "\n",
    "class jerarquico(MRJob):\n",
    "    \n",
    "    OUTPUT_PROTOCOL = RawValueProtocol\n",
    "    \n",
    "    def mapper(self,_, line):\n",
    "        linea=line.split(\";\") \n",
    "        \n",
    "        mensaje=linea[4] # Recogemos el mensaje de la posición 4 de la línea\n",
    "        tipoMensaje=linea[5] #Recogemos de la posición 5, si es una pregunta o respuesta\n",
    "       \n",
    "        if tipoMensaje==\"question\": \n",
    "            idMensaje=linea[0] #Almacenamos el id único del mensaje\n",
    "            yield idMensaje,(tipoMensaje,mensaje)\n",
    "        else:\n",
    "            idMensaje=linea[7] #Almacenamos el identificador del mensaje idMensaje  \n",
    "            yield idMensaje,(tipoMensaje,mensaje)\n",
    "     \n",
    "    def reducer(self, key, values):\n",
    "        listaValores=[]\n",
    "        listaPrincipal=[]\n",
    "        listaAuxiliar=[] \n",
    "        \n",
    "        for v in values: #Metemos los valores que vienen en un matriz\n",
    "            listaValores.append(v) #Matriz que contiene el tipo de mensaje y el mensaje asociado \n",
    "        \n",
    "        for valor in listaValores:\n",
    "            if valor[0]==\"question\":#Si es una pregunta la metemos en la lista principal\n",
    "                listaPrincipal.append(valor[1])\n",
    "            else:\n",
    "                listaAuxiliar.append(valor[1]) # Si son respuestas, las vamos agregando a una lista\n",
    "        \n",
    "        listaPrincipal.append(listaAuxiliar) #agregamos la lista de respuestas a la lista principal\n",
    "        \n",
    "        #Conversion a XML indicando en el raiz el id del mensaje\n",
    "        yield \"Creada linea XML: \" ,xmlify.dumps(listaPrincipal,root = key) \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    jerarquico.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/jerarquico.root.20201217.194540.764920\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/jerarquico.root.20201217.194540.764920/output\n",
      "Streaming final output from /tmp/jerarquico.root.20201217.194540.764920/output...\n",
      "Removing temp directory /tmp/jerarquico.root.20201217.194540.764920...\n"
     ]
    }
   ],
   "source": [
    "!python jerarquico.py archivos_datos/foros.csv > e_jerarquica.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capítulo 6\n",
    "\n",
    "6.3 Patrones de organización de datos.\n",
    "\n",
    "6.3.1 Estructuración jerárquica\n",
    "\n",
    "Prototipo - Esta segunda versión vamos a usar la estructura diccionarios de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing jerarquicoV2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile jerarquicoV2.py\n",
    "#!/usr/bin/env python\n",
    "#Usamos el archivo foros.csv\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.protocol import RawValueProtocol\n",
    "import xmlify\n",
    "\n",
    "class jerarquicoV2(MRJob):\n",
    "    OUTPUT_PROTOCOL = RawValueProtocol\n",
    "    def mapper(self,_, line):\n",
    "        linea=line.split(\";\") # Cada línea es un mensaje del foro (pregunta, respuesta o comentario)\n",
    "        \n",
    "        mensaje=linea[4] # Recogemos el mensaje de la posición 4 de la línea\n",
    "        tipoMensaje=linea[5] #Recogemos de la posición 5, si es una pregunta, respuesta o comentario\n",
    "        \n",
    "        if tipoMensaje==\"question\": \n",
    "            idMensaje=linea[0] #Almacenamos el id único del mensaje\n",
    "            yield idMensaje,(tipoMensaje,mensaje)\n",
    "        else:\n",
    "            idPadre=linea[7] #Almacenamos el identificador del mensaje idMensaje  \n",
    "            yield idPadre,(tipoMensaje,mensaje)\n",
    "     \n",
    "    def reducer(self, key, values):\n",
    "        diccionario=dict() #Para el caso que usemos diccionarios\n",
    "        matrizParaXML=[]\n",
    "        listaPrincipal=[]\n",
    "        listaAuxiliar=[]\n",
    "        \n",
    "        for v in values: #Metemos los valores que vienen en un matriz\n",
    "            matrizParaXML.append(v) #Matriz que contiene el tipo de mensaje y el mensaje asociado \n",
    "        \n",
    "        for valor in matrizParaXML:\n",
    "            if valor[0]==\"question\":#Si es una pregunta la metemos en la lista principal\n",
    "                listaPrincipal.append(valor[1])\n",
    "            else:\n",
    "                listaAuxiliar.append(valor[1]) # Si son respuestas, las vamos agregando a una lista\n",
    "        \n",
    "        listaPrincipal.append(listaAuxiliar) #agregamos la lista de respuestas a la lista principal \n",
    "        diccionario[key]=listaPrincipal #Para el caso que usemos diccionarios\n",
    "        yield key,xmlify.dumps(diccionario) # Conversion a XML para el caso que usemos diccionarios\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    jerarquicoV2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\cyber\\AppData\\Local\\Temp\\jerarquicoV2.manuel.20201211.191824.267729\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\cyber\\AppData\\Local\\Temp\\jerarquicoV2.manuel.20201211.191824.267729\\output\n",
      "Streaming final output from C:\\Users\\cyber\\AppData\\Local\\Temp\\jerarquicoV2.manuel.20201211.191824.267729\\output...\n",
      "Removing temp directory C:\\Users\\cyber\\AppData\\Local\\Temp\\jerarquicoV2.manuel.20201211.191824.267729...\n"
     ]
    }
   ],
   "source": [
    "!python jerarquicoV2.py archivos_datos/foros.csv > e_jerarquica.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /usr/lib/hadoop/bin...\n",
      "Found hadoop binary: /usr/lib/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.6.0\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop...\n",
      "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
      "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
      "Creating temp directory /tmp/jerarquico.root.20201217.194810.916578\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/jerarquico.root.20201217.194810.916578/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/jerarquico.root.20201217.194810.916578/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.15.1.jar] /tmp/streamjob677361302635334804.jar tmpDir=null\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.4:8032\n",
      "  Connecting to ResourceManager at yarnmaster/172.18.0.4:8032\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1608233950986_0001\n",
      "  Submitted application application_1608233950986_0001\n",
      "  The url to track the job: http://yarnmaster:8088/proxy/application_1608233950986_0001/\n",
      "  Running job: job_1608233950986_0001\n",
      "  Job job_1608233950986_0001 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "  Task Id : attempt_1608233950986_0001_m_000000_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "  Task Id : attempt_1608233950986_0001_m_000001_0, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "  Task Id : attempt_1608233950986_0001_m_000000_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "  Task Id : attempt_1608233950986_0001_m_000001_1, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "  Task Id : attempt_1608233950986_0001_m_000000_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "  Task Id : attempt_1608233950986_0001_m_000001_2, Status : FAILED\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "   map 100% reduce 100%\n",
      "  Job job_1608233950986_0001 failed with state FAILED due to: Task failed task_1608233950986_0001_m_000000\n",
      "Job failed as tasks failed. failedMaps:1 failedReduces:0\n",
      "\n",
      "  Job not successful!\n",
      "  Streaming Command Failed!\n",
      "Counters: 14\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tFailed map tasks=7\n",
      "\t\tKilled map tasks=1\n",
      "\t\tKilled reduce tasks=1\n",
      "\t\tLaunched map tasks=8\n",
      "\t\tOther local map tasks=6\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=166649856\n",
      "\t\tTotal time spent by all map tasks (ms)=162744\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=162744\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=162744\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=0\n",
      "\t\tPhysical memory (bytes) snapshot=0\n",
      "\t\tVirtual memory (bytes) snapshot=0\n",
      "Scanning logs for probable cause of failure...\n",
      "Looking for history log in hdfs:///tmp/hadoop-yarn/staging...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for history log in /usr/lib/hadoop-mapreduce/logs...\n",
      "Looking for history log in /var/log/hadoop-yarn...\n",
      "Probable cause of failure:\n",
      "\n",
      "Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:538)\n",
      "\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n",
      "\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n",
      "\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n",
      "\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:459)\n",
      "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)\n",
      "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)\n",
      "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)\n",
      "\n",
      "Step 1 of 1 failed: Command '['/usr/lib/hadoop/bin/hadoop', 'jar', '/usr/lib/hadoop-mapreduce/hadoop-streaming.jar', '-files', 'hdfs:///user/root/tmp/mrjob/jerarquico.root.20201217.194810.916578/files/wd/jerarquico.py#jerarquico.py,hdfs:///user/root/tmp/mrjob/jerarquico.root.20201217.194810.916578/files/wd/mrjob.zip#mrjob.zip,hdfs:///user/root/tmp/mrjob/jerarquico.root.20201217.194810.916578/files/wd/setup-wrapper.sh#setup-wrapper.sh', '-input', 'hdfs:///archivos_datos/foros.csv', '-output', 'hdfs:///user/root/tmp/mrjob/jerarquico.root.20201217.194810.916578/output', '-mapper', '/bin/sh -ex setup-wrapper.sh /opt/anaconda/bin/python3.7 jerarquico.py --step-num=0 --mapper', '-reducer', '/bin/sh -ex setup-wrapper.sh /opt/anaconda/bin/python3.7 jerarquico.py --step-num=0 --reducer']' returned non-zero exit status 256.\n"
     ]
    }
   ],
   "source": [
    "!python jerarquico.py hdfs:///archivos_datos/foros.csv -r hadoop --python-bin /opt/anaconda/bin/python3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
